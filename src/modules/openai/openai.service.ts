import { Injectable, HttpException, HttpStatus, Logger } from '@nestjs/common';
import { ConfigService } from '@nestjs/config';
import OpenAI from 'openai';
import { RoastRequestData } from '../../shared/types/github.types';
import { PROMPT_TEMPLATES } from '../../shared/constants/prompt-templates.constants';

@Injectable()
export class OpenAIService {
  private readonly logger = new Logger(OpenAIService.name);
  private openai: OpenAI;

  constructor(private readonly configService: ConfigService) {
    const apiKey = this.configService.get<string>('openai.apiKey');
    
    if (!apiKey) {
      throw new Error('OpenAI API key is not configured');
    }
    
    this.openai = new OpenAI({
      apiKey,
    });
  }

  async generateRoast(
    roastData: RoastRequestData,
    temperature: number = 0.7,
  ): Promise<string> {
    try {
      this.logger.log(`Generating roast for ${roastData.username} with temperature ${temperature}`);
      
      const prompt = this.buildPrompt(roastData);
      
      const completion = await this.openai.chat.completions.create({
        model: this.configService.get<string>('openai.model'),
        messages: [
          {
            role: 'system',
            content: PROMPT_TEMPLATES.roast.system,
          },
          {
            role: 'user',
            content: prompt,
          },
        ],
        temperature: Math.min(Math.max(temperature, 0.1), 2.0),
        max_tokens: this.configService.get<number>('openai.maxTokens'),
        top_p: 0.9,
        frequency_penalty: 0.5,
        presence_penalty: 0.3,
      });

      const roast = completion.choices[0].message.content;
      
      if (!roast) {
        throw new Error('No content generated by OpenAI');
      }

      this.logger.log(`Successfully generated roast for ${roastData.username}`);
      return roast;
    } catch (error) {
      this.logger.error(`Failed to generate roast: ${error.message}`);
      
      if (error instanceof OpenAI.APIError) {
        switch (error.status) {
          case 401:
            throw new HttpException(
              'OpenAI authentication failed',
              HttpStatus.INTERNAL_SERVER_ERROR,
            );
          case 429:
            throw new HttpException(
              'OpenAI rate limit exceeded',
              HttpStatus.TOO_MANY_REQUESTS,
            );
          default:
            throw new HttpException(
              'Failed to generate roast. Please try again.',
              HttpStatus.INTERNAL_SERVER_ERROR,
            );
        }
      }
      
      throw new HttpException(
        'Failed to generate roast. Please try again.',
        HttpStatus.INTERNAL_SERVER_ERROR,
      );
    }
  }

  private buildPrompt(data: RoastRequestData): string {
    const recentReposText = data.recentRepos
      .map(repo => 
        `- ${repo.name}: ${repo.description || 'No description'} (${repo.language || 'No language'}) - ${repo.stars} â­, ${repo.forks} ðŸ´ - Updated ${repo.daysSinceUpdate} days ago`
      )
      .join('\n');

    const languagesText = Object.entries(data.languages)
      .map(([lang, count]) => `${lang} (${count} repos)`)
      .join(', ');

    return PROMPT_TEMPLATES.roast.user({
      ...data,
      recentReposText,
      languagesText,
      followerRatio: data.following > 0 
        ? (data.followers / data.following).toFixed(2) 
        : 'N/A',
      starPerRepo: data.publicRepos > 0 
        ? (data.totalStars / data.publicRepos).toFixed(2) 
        : '0',
    });
  }
}